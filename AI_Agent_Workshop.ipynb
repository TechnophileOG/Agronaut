{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TechnophileOG/Agronaut/blob/main/AI_Agent_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA7N6fuzcerU"
      },
      "source": [
        "# AI Agent from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlWEaLSdcerW"
      },
      "source": [
        "## What will we learn? How can it help you?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSFeYlxkcerX"
      },
      "source": [
        "### Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQPWREELcerX",
        "outputId": "747463bc-34ac-4a47-f923-d7e81e7e6be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Requirement already satisfied: ping3 in /usr/local/lib/python3.10/dist-packages (4.0.8)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install ping3\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain\n",
        "##### Sequence of Actions is Hard-Coded\n",
        "![Chain](https://drive.google.com/uc?id=1svRaRr-7AgfD2AEiX9Ke9lxXRnToK3i8)\n",
        "\n",
        "### Agent\n",
        "![Agent](https://drive.google.com/uc?id=1dabLbC_eN-Xy2f8dYctAMtopVcC4y7Au)"
      ],
      "metadata": {
        "id": "EoUQgH9AjN8A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gxnt_dfcerY"
      },
      "source": [
        "## The Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofEMW0K6cerY"
      },
      "outputs": [],
      "source": [
        "system_prompt_template = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Action_Response.\n",
        "At the end of the loop you output an Answer.\n",
        "\n",
        "Use Thought to understand the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Action_Response will be the result of running those actions.\n",
        "\n",
        "Thought and Action should occur in the same turn.\n",
        "\n",
        "If you have multiple actions to run, you can run them in consecutive turns.\n",
        "\n",
        "Your available actions are:\n",
        "{tool_descriptions}\n",
        "\n",
        "\n",
        "# Example session:\n",
        "\n",
        "Question: what is the response time category for something.com?\n",
        "Thought: I should check the response time for the web page first.\n",
        "Action:\n",
        "\n",
        "{{\n",
        "  \"function_name\": \"get_response_time\",\n",
        "  \"function_params\": {{\n",
        "    \"url\": \"something.com\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Action_Response: 5\n",
        "\n",
        "Thought: I should now output the response time ranking.\n",
        "\n",
        "Action:\n",
        "\n",
        "{{\n",
        "  \"function_name\": \"get_response_time_category\",\n",
        "  \"function_params\": {{\n",
        "    \"response_time\": 5\n",
        "  }}\n",
        "}}\n",
        "\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Action_Response: Fast\n",
        "\n",
        "You then output:\n",
        "\n",
        "Answer: The response time category for something.com is Fast.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q15d2mIxcerY"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7hhnHwzcerZ"
      },
      "outputs": [],
      "source": [
        "# Get Response Time\n",
        "from ping3 import ping\n",
        "\n",
        "def get_response_time(url):\n",
        "    response_time = ping(url, unit='ms') # 's' for seconds and 'ms' for milliseconds\n",
        "    if response_time is None:\n",
        "        return -1\n",
        "    else:\n",
        "        return response_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl2JOo6HcerZ"
      },
      "outputs": [],
      "source": [
        "# Get Response Time Category\n",
        "def get_response_time_category(response_time):\n",
        "    if response_time <= 10:\n",
        "        return \"Fast\"\n",
        "    if response_time > 10:\n",
        "        return \"Slow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wchlhc5cerZ"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"function_name\": \"get_response_time\",\n",
        "        \"function_call\": get_response_time,\n",
        "        \"function_params\": [\n",
        "            {   \"param_name\": \"url\",\n",
        "                \"type\": str\n",
        "            }\n",
        "        ],\n",
        "        \"example_input\": \"google.com\",\n",
        "        \"return_type\": int,\n",
        "        \"description\": \"Returns the response time of a website in ms, returns -1 if the website is unreachable\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"function_name\": \"get_response_time_category\",\n",
        "        \"function_call\": get_response_time_category,\n",
        "        \"function_params\": [\n",
        "            {   \"param_name\": \"response_time\",\n",
        "                \"type\": int\n",
        "            }\n",
        "        ],\n",
        "        \"example_input\": \"5\",\n",
        "        \"return_type\": str,\n",
        "        \"description\": \"Returns the category based upon the response time of a website\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvXIXfTEcerZ"
      },
      "source": [
        "### Add Tools to the Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdZb7aWwcera"
      },
      "outputs": [],
      "source": [
        "def get_tool_descriptions(tools):\n",
        "\n",
        "    tool_descriptions = \"\"\n",
        "\n",
        "    for tool in tools:\n",
        "      tool_descriptions += \"\\n\"\n",
        "      tool_descriptions += tool['function_name'] + \":\"\n",
        "      tool_descriptions += \"\\nDescription: \" + tool[\"description\"]\n",
        "      tool_descriptions += \"\\nParameters:\"\n",
        "      for param in tool[\"function_params\"]:\n",
        "        tool_descriptions += \"\\n\\t\" + param[\"param_name\"] + \": \" + str(param[\"type\"])\n",
        "      tool_descriptions += \"\\n\\tReturn type: \" + str(tool[\"return_type\"])\n",
        "      tool_descriptions += \"\\ne.g. \" + tool[\"function_name\"] + \": \" + tool[\"example_input\"]\n",
        "      tool_descriptions += \"\\n\"\n",
        "\n",
        "    return tool_descriptions\n",
        "\n",
        "tool_descriptions=get_tool_descriptions(tools)\n",
        "print(tool_descriptions)\n",
        "\n",
        "system_prompt = system_prompt_template.format(tool_descriptions=tool_descriptions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCcaLCslcera"
      },
      "source": [
        "### Helper Function to extract JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRtAaL2acera"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def extract_json(text_response):\n",
        "    pattern = r'\\{.*?\\}'\n",
        "    matches = re.finditer(pattern, text_response, re.DOTALL)\n",
        "    json_objects = []\n",
        "\n",
        "    for match in matches:\n",
        "        json_str = extend_search_new(text_response, match.span())\n",
        "        try:\n",
        "            json_obj = json.loads(json_str)\n",
        "            json_objects.append(json_obj)\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "    return json_objects if json_objects else None\n",
        "\n",
        "def extend_search_new(text, span):\n",
        "    start, end = span\n",
        "    nest_count = 1  # Starts with 1 since we know '{' is at the start position\n",
        "    for i in range(end, len(text)):\n",
        "        if text[i] == '{':\n",
        "            nest_count += 1\n",
        "        elif text[i] == '}':\n",
        "            nest_count -= 1\n",
        "            if nest_count == 0:\n",
        "                return text[start:i+1]\n",
        "    return text[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga4axI8Zcera"
      },
      "source": [
        "## Creating the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ8Zub-gcerb",
        "outputId": "45620013-3b68-4e93-9d85-0aa79dfa09b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "# import os\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "402L0fGvcerb"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_conversation(messages, model = \"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "        )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORr1eq74cerb"
      },
      "outputs": [],
      "source": [
        "available_actions = {\n",
        "    tool[\"function_name\"]: tool[\"function_call\"] for tool in tools\n",
        "}\n",
        "\n",
        "available_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDtCwT7cerb"
      },
      "outputs": [],
      "source": [
        "user_prompt = \"what is the response time category for youtube.com?\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": user_prompt},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu076G8_cerb"
      },
      "source": [
        "# Coversation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmbVE4Fscerb"
      },
      "outputs": [],
      "source": [
        "turn_count = 1\n",
        "max_turns = 10\n",
        "\n",
        "while turn_count < max_turns:\n",
        "    print (f\"Loop: {turn_count}\")\n",
        "    print(\"-------------------------------------------------------------\")\n",
        "    turn_count += 1\n",
        "\n",
        "    response = generate_text_with_conversation(messages, model=\"gpt-3.5-turbo\") #\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "    print(response)\n",
        "    json_function = extract_json(response)\n",
        "\n",
        "    if json_function:\n",
        "            function_name = json_function[0]['function_name']\n",
        "            function_parms = json_function[0]['function_params']\n",
        "            if function_name not in available_actions:\n",
        "                raise Exception(f\"Unknown action: {function_name}: {function_parms}\")\n",
        "            print(f\" -- running {function_name} {function_parms}\")\n",
        "            action_function = available_actions[function_name]\n",
        "            #call the function\n",
        "            result = action_function(**function_parms)\n",
        "            function_result_message = f\"Action_Response: {result}\"\n",
        "            messages.append({\"role\": \"user\", \"content\": function_result_message})\n",
        "            print(function_result_message)\n",
        "    else:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}